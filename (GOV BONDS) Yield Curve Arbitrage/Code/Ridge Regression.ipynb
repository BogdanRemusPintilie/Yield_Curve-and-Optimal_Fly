{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.5534157399729221\n",
      "R^2 Score: 0.7644238294806261\n",
      "Best alpha: 1.0\n",
      "Best cross-validated score: 0.8580311433595791\n",
      "\n",
      "Intercept (b0): -0.16439816142176186\n",
      "Coefficient for Inflation (b_Inflation): 0.2753833031080488\n",
      "Coefficient for Real GDP growth (b_Real GDP growth): -0.15004377992505685\n",
      "Coefficient for Unemployment rate (b_Unemployment rate): -0.15210662580791917\n",
      "Coefficient for FF rate (b_FF rate): -0.23273985131752115\n",
      "Coefficient for Debt (b_Debt): -0.16544316489726058\n",
      "Coefficient for ISM Services PMI (b_ISM Services PMI): -0.04405496912507989\n",
      "Coefficient for ISM Manufacturing PMI (b_ISM Manufacturing PMI): 0.0873395069905247\n",
      "Coefficient for Economic Surprise Index (b_Economic Surprise Index): 0.15220443287733537\n",
      "Coefficient for 10-Year Breakeven Inflation Rate (b_10-Year Breakeven Inflation Rate): -0.12294237931402326\n",
      "Coefficient for SOFR (b_SOFR): -0.22799545464907667\n",
      "Coefficient for M2 (b_M2): 0.01861981023512746\n",
      "Coefficient for VIX (b_VIX): 0.0743578712420833\n",
      "Coefficient for IND PROD (b_IND PROD): 0.07115889633378458\n",
      "Coefficient for S&P500 (b_S&P500): -0.07618338927797272\n",
      "Coefficient for WTI (b_WTI): -0.0868641689861715\n",
      "Coefficient for 10Y bid-to-cover ratio (b_10Y bid-to-cover ratio): -0.012117987638708916\n",
      "Coefficient for 10Y Treasury Auction Rate (b_10Y Treasury Auction Rate): -0.03353309855309544\n",
      "Coefficient for 10Y TNote COT Index (b_10Y TNote COT Index): -0.04663597854572804\n",
      "Coefficient for Adj Close (b_Adj Close): 0.25057885142915637\n",
      "\n",
      "Mathematical formula for PC1:\n",
      "PC1 = -0.1644 + (0.2754) * Inflation + (-0.1500) * Real GDP growth + (-0.1521) * Unemployment rate + (-0.2327) * FF rate + (-0.1654) * Debt + (-0.0441) * ISM Services PMI + (0.0873) * ISM Manufacturing PMI + (0.1522) * Economic Surprise Index + (-0.1229) * 10-Year Breakeven Inflation Rate + (-0.2280) * SOFR + (0.0186) * M2 + (0.0744) * VIX + (0.0712) * IND PROD + (-0.0762) * S&P500 + (-0.0869) * WTI + (-0.0121) * 10Y bid-to-cover ratio + (-0.0335) * 10Y Treasury Auction Rate + (-0.0466) * 10Y TNote COT Index + (0.2506) * Adj Close\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\Bogdan\\\\OneDrive - University of Warwick\\\\Desktop\\\\Projects\\\\(GOV BONDS) Yield Curve Arbitrage\\\\Data\\\\Regress data.xlsx\")\n",
    "\n",
    "X = df.drop(columns=['PC1', 'PC2', 'PC3', 'Date']) #just exogenous variables\n",
    "y = df['PC1']  # The target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#random_state is to get the same test training sets irrespective of how many runs u do and 42 doesn't stand for anything logical\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler() #Basically what happens is you subtract the mean then divide by the std. Is is simple standardisation like the one in PCA. And the values that you get once you standardise cause they not the same right are calle z-score(s) and have a mean=0 and std=1\n",
    "X_train_scaled = scaler.fit_transform(X_train) #fit_transform just applies the scaler to the data like each feature/column.\n",
    "X_test_scaled = scaler.transform(X_test) #here fit is missing because I need the fit to be the same as the one in the training so the transform applies the fit from the training to the data like see fit_transform as 2 separate methods (fit calcualtes the mean and std of each column and transform applies the standardisation)\n",
    "\n",
    "# Fit the Ridge Regression Model\n",
    "ridge_reg = Ridge(alpha=1.0)  # ridge regression becasue of the multicollinearity (when predictors are highly correlated) i mean ridge with alpha=0 is the same as OLS but with alpha you have a greater penlaty for high coeff. Like OLS chooses the coef s.t. it minmises a cost function, that alpha is timed by the sum of coeff and added to the cost function so the coeff will be smaller once u do that and that helps with avoiding overfitting (although this is ehh cause it's not blac and withe as in waht is best to have). so OLS's cost function is the sume of squared residuals (actual - predicted) so it is prone to overfit.\n",
    "ridge_reg.fit(X_train_scaled, y_train) #the model learns the relationships between the input features (X_train_scaled) and the target variable (y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = ridge_reg.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_score = ridge_reg.score(X_test_scaled, y_test) #this is r squared (this is for the model that was created in the training stage and now used test data) So ideally u want 1. Now if the test data is like 1 day then you can think that you overfit but if it is 50% of the data then u probably did smth pretty good. hope u got the idea with overfit but again if it works well during test and the test is sufficintly large then gg\n",
    "\n",
    "print(f'Root Mean Squared Error: {rmse}') #so on avergae I am missing by 0.83\n",
    "print(f'R^2 Score: {r2_score}') #again like this a debate of waht a good R**2 value is fora 20% test data and a ridge regress\n",
    "\n",
    "#Tuning the alpha hyperparameter using GridSearchCV\n",
    "alpha_values = {'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "ridge_cv = GridSearchCV(Ridge(), alpha_values, cv=5) # cv=5 = five fold cross validation. The model is trained on 4 subsets and validated on the remaining one. This process is repeated 5 times (each time with a different validation subset), and the results are averaged to assess the model's performance.\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Best alpha: {ridge_cv.best_params_[\"alpha\"]}') #retrieves the best alpha\n",
    "print(f'Best cross-validated score: {ridge_cv.best_score_}') #like best R**2 using th ebest alpha\n",
    "print('')\n",
    "\n",
    "#either way u spin it you have to choose a test size (%) and an alpha based on other aspects and not grid search cause drig search will make alpha 0 and test data small so unless u get better R^2 values for higher alpha and higher test then grid is illogical and the test_data split is pretty much depnedent on your horizon, alph is for how much u wanna avoid overfitting\n",
    "\n",
    "# Extract the coefficients and intercept\n",
    "coefficients = ridge_reg.coef_\n",
    "intercept = ridge_reg.intercept_\n",
    "\n",
    "# Display the coefficients and intercept\n",
    "print(\"Intercept (b0):\", intercept)\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    print(f\"Coefficient for {feature} (b_{feature}):\", coef)\n",
    "\n",
    "# Create the mathematical formula\n",
    "formula = \"PC1 = \" + f\"{intercept:.4f}\"\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    formula += f\" + ({coef:.4f}) * {feature}\"\n",
    "\n",
    "print(\"\\nMathematical formula for PC1:\")\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.5684402110001177\n",
      "R^2 Score: 0.5858852817378967\n",
      "Best alpha: 1.0\n",
      "Best cross-validated score: 0.5612052348345788\n",
      "\n",
      "Intercept (b0): -0.07462830646156958\n",
      "Coefficient for Inflation (b_Inflation): 0.011888895892125717\n",
      "Coefficient for Real GDP growth (b_Real GDP growth): -0.011342971597812002\n",
      "Coefficient for Unemployment rate (b_Unemployment rate): 0.01253633421567038\n",
      "Coefficient for FF rate (b_FF rate): -0.018044066502428402\n",
      "Coefficient for Debt (b_Debt): 0.1019312697159698\n",
      "Coefficient for ISM Services PMI (b_ISM Services PMI): 0.00021189928918384504\n",
      "Coefficient for ISM Manufacturing PMI (b_ISM Manufacturing PMI): 0.0024165747191477183\n",
      "Coefficient for Economic Surprise Index (b_Economic Surprise Index): -0.024846157736671953\n",
      "Coefficient for 10-Year Breakeven Inflation Rate (b_10-Year Breakeven Inflation Rate): 0.21003214156842698\n",
      "Coefficient for SOFR (b_SOFR): -0.011428926884233165\n",
      "Coefficient for M2 (b_M2): -0.034531249402018044\n",
      "Coefficient for VIX (b_VIX): -0.009146324221595573\n",
      "Coefficient for IND PROD (b_IND PROD): -0.07143881554510478\n",
      "Coefficient for S&P500 (b_S&P500): -0.011425792050827513\n",
      "Coefficient for WTI (b_WTI): 0.05775923293275172\n",
      "Coefficient for 10Y bid-to-cover ratio (b_10Y bid-to-cover ratio): 0.03896320227465702\n",
      "Coefficient for 10Y Treasury Auction Rate (b_10Y Treasury Auction Rate): 0.1593514904680576\n",
      "Coefficient for 10Y TNote COT Index (b_10Y TNote COT Index): -0.15905310459002206\n",
      "Coefficient for Adj Close (b_Adj Close): -0.18900471459453705\n",
      "\n",
      "Mathematical formula for PC2:\n",
      "PC2 = -0.0746 + (0.0119) * Inflation + (-0.0113) * Real GDP growth + (0.0125) * Unemployment rate + (-0.0180) * FF rate + (0.1019) * Debt + (0.0002) * ISM Services PMI + (0.0024) * ISM Manufacturing PMI + (-0.0248) * Economic Surprise Index + (0.2100) * 10-Year Breakeven Inflation Rate + (-0.0114) * SOFR + (-0.0345) * M2 + (-0.0091) * VIX + (-0.0714) * IND PROD + (-0.0114) * S&P500 + (0.0578) * WTI + (0.0390) * 10Y bid-to-cover ratio + (0.1594) * 10Y Treasury Auction Rate + (-0.1591) * 10Y TNote COT Index + (-0.1890) * Adj Close\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\Bogdan\\\\OneDrive - University of Warwick\\\\Desktop\\\\Projects\\\\(GOV BONDS) Yield Curve Arbitrage\\\\Data\\\\Regress data.xlsx\")\n",
    "\n",
    "X = df.drop(columns=['PC1', 'PC2', 'PC3', 'Date']) #just exogenous variables\n",
    "y = df['PC2']  # The target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#random_state is to get the same test training sets irrespective of how many runs u do and 42 doesn't stand for anything logical\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler() #Basically what happens is you subtract the mean then divide by the std. Is is simple standardisation like the one in PCA. And the values that you get once you standardise cause they not the same right are calle z-score(s) and have a mean=0 and std=1\n",
    "X_train_scaled = scaler.fit_transform(X_train) #fit_transform just applies the scaler to the data like each feature/column.\n",
    "X_test_scaled = scaler.transform(X_test) #here fit is missing because I need the fit to be the same as the one in the training so the transform applies the fit from the training to the data like see fit_transform as 2 separate methods (fit calcualtes the mean and std of each column and transform applies the standardisation)\n",
    "\n",
    "# Fit the Ridge Regression Model\n",
    "ridge_reg = Ridge(alpha=1.0)  # ridge regression becasue of the multicollinearity (when predictors are highly correlated) i mean ridge with alpha=0 is the same as OLS but with alpha you have a greater penlaty for high coeff. Like OLS chooses the coef s.t. it minmises a cost function, that alpha is timed by the sum of coeff and added to the cost function so the coeff will be smaller once u do that and that helps with avoiding overfitting (although this is ehh cause it's not blac and withe as in waht is best to have). so OLS's cost function is the sume of squared residuals (actual - predicted) so it is prone to overfit.\n",
    "ridge_reg.fit(X_train_scaled, y_train) #the model learns the relationships between the input features (X_train_scaled) and the target variable (y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = ridge_reg.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_score = ridge_reg.score(X_test_scaled, y_test) #this is r squared (this is for the model that was created in the training stage and now used test data) So ideally u want 1. Now if the test data is like 1 day then you can think that you overfit but if it is 50% of the data then u probably did smth pretty good. hope u got the idea with overfit but again if it works well during test and the test is sufficintly large then gg\n",
    "\n",
    "print(f'Root Mean Squared Error: {rmse}') #so on avergae I am missing by 0.83\n",
    "print(f'R^2 Score: {r2_score}') #again like this a debate of waht a good R**2 value is fora 20% test data and a ridge regress\n",
    "\n",
    "#Tuning the alpha hyperparameter using GridSearchCV\n",
    "alpha_values = {'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "ridge_cv = GridSearchCV(Ridge(), alpha_values, cv=5) # cv=5 = five fold cross validation. The model is trained on 4 subsets and validated on the remaining one. This process is repeated 5 times (each time with a different validation subset), and the results are averaged to assess the model's performance.\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Best alpha: {ridge_cv.best_params_[\"alpha\"]}') #retrieves the best alpha\n",
    "print(f'Best cross-validated score: {ridge_cv.best_score_}') #like best R**2 using th ebest alpha\n",
    "print('')\n",
    "\n",
    "#either way u spin it you have to choose a test size (%) and an alpha based on other aspects and not grid search cause drig search will make alpha 0 and test data small so unless u get better R^2 values for higher alpha and higher test then grid is illogical and the test_data split is pretty much depnedent on your horizon, alph is for how much u wanna avoid overfitting\n",
    "\n",
    "# Extract the coefficients and intercept\n",
    "coefficients = ridge_reg.coef_\n",
    "intercept = ridge_reg.intercept_\n",
    "\n",
    "# Display the coefficients and intercept\n",
    "print(\"Intercept (b0):\", intercept)\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    print(f\"Coefficient for {feature} (b_{feature}):\", coef)\n",
    "\n",
    "# Create the mathematical formula\n",
    "formula = \"PC2 = \" + f\"{intercept:.4f}\"\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    formula += f\" + ({coef:.4f}) * {feature}\"\n",
    "\n",
    "print(\"\\nMathematical formula for PC2:\")\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.4384718585376833\n",
      "R^2 Score: -1.207047606888867\n",
      "Best alpha: 1.0\n",
      "Best cross-validated score: 0.3498352668331353\n",
      "\n",
      "Intercept (b0): 0.022213107834411203\n",
      "Coefficient for Inflation (b_Inflation): 0.008304541553752293\n",
      "Coefficient for Real GDP growth (b_Real GDP growth): 0.15013603798048772\n",
      "Coefficient for Unemployment rate (b_Unemployment rate): -0.03694915781280638\n",
      "Coefficient for FF rate (b_FF rate): -0.03869033849985782\n",
      "Coefficient for Debt (b_Debt): -0.025595648858034458\n",
      "Coefficient for ISM Services PMI (b_ISM Services PMI): 0.0024269723341735355\n",
      "Coefficient for ISM Manufacturing PMI (b_ISM Manufacturing PMI): 0.021525584649443014\n",
      "Coefficient for Economic Surprise Index (b_Economic Surprise Index): 0.03343252559673289\n",
      "Coefficient for 10-Year Breakeven Inflation Rate (b_10-Year Breakeven Inflation Rate): 0.059732587186613784\n",
      "Coefficient for SOFR (b_SOFR): -0.03950350167857114\n",
      "Coefficient for M2 (b_M2): 0.036566024354549795\n",
      "Coefficient for VIX (b_VIX): -0.05670844886286051\n",
      "Coefficient for IND PROD (b_IND PROD): 0.011387218563683937\n",
      "Coefficient for S&P500 (b_S&P500): 0.006968333892674428\n",
      "Coefficient for WTI (b_WTI): -0.030238591889106745\n",
      "Coefficient for 10Y bid-to-cover ratio (b_10Y bid-to-cover ratio): 0.05272927455128205\n",
      "Coefficient for 10Y Treasury Auction Rate (b_10Y Treasury Auction Rate): -0.0640671461276195\n",
      "Coefficient for 10Y TNote COT Index (b_10Y TNote COT Index): -0.03908655434086242\n",
      "Coefficient for Adj Close (b_Adj Close): -0.021206291227319596\n",
      "\n",
      "Mathematical formula for PC3:\n",
      "PC3 = 0.0222 + (0.0083) * Inflation + (0.1501) * Real GDP growth + (-0.0369) * Unemployment rate + (-0.0387) * FF rate + (-0.0256) * Debt + (0.0024) * ISM Services PMI + (0.0215) * ISM Manufacturing PMI + (0.0334) * Economic Surprise Index + (0.0597) * 10-Year Breakeven Inflation Rate + (-0.0395) * SOFR + (0.0366) * M2 + (-0.0567) * VIX + (0.0114) * IND PROD + (0.0070) * S&P500 + (-0.0302) * WTI + (0.0527) * 10Y bid-to-cover ratio + (-0.0641) * 10Y Treasury Auction Rate + (-0.0391) * 10Y TNote COT Index + (-0.0212) * Adj Close\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\Bogdan\\\\OneDrive - University of Warwick\\\\Desktop\\\\Projects\\\\(GOV BONDS) Yield Curve Arbitrage\\\\Data\\\\Regress data.xlsx\")\n",
    "\n",
    "X = df.drop(columns=['PC1', 'PC2', 'PC3', 'Date']) #just exogenous variables\n",
    "y = df['PC3']  # The target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#random_state is to get the same test training sets irrespective of how many runs u do and 42 doesn't stand for anything logical\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler() #Basically what happens is you subtract the mean then divide by the std. Is is simple standardisation like the one in PCA. And the values that you get once you standardise cause they not the same right are calle z-score(s) and have a mean=0 and std=1\n",
    "X_train_scaled = scaler.fit_transform(X_train) #fit_transform just applies the scaler to the data like each feature/column.\n",
    "X_test_scaled = scaler.transform(X_test) #here fit is missing because I need the fit to be the same as the one in the training so the transform applies the fit from the training to the data like see fit_transform as 2 separate methods (fit calcualtes the mean and std of each column and transform applies the standardisation)\n",
    "\n",
    "# Fit the Ridge Regression Model\n",
    "ridge_reg = Ridge(alpha=1.0)  # ridge regression becasue of the multicollinearity (when predictors are highly correlated) i mean ridge with alpha=0 is the same as OLS but with alpha you have a greater penlaty for high coeff. Like OLS chooses the coef s.t. it minmises a cost function, that alpha is timed by the sum of coeff and added to the cost function so the coeff will be smaller once u do that and that helps with avoiding overfitting (although this is ehh cause it's not blac and withe as in waht is best to have). so OLS's cost function is the sume of squared residuals (actual - predicted) so it is prone to overfit.\n",
    "ridge_reg.fit(X_train_scaled, y_train) #the model learns the relationships between the input features (X_train_scaled) and the target variable (y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = ridge_reg.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_score = ridge_reg.score(X_test_scaled, y_test) #this is r squared (this is for the model that was created in the training stage and now used test data) So ideally u want 1. Now if the test data is like 1 day then you can think that you overfit but if it is 50% of the data then u probably did smth pretty good. hope u got the idea with overfit but again if it works well during test and the test is sufficintly large then gg\n",
    "\n",
    "print(f'Root Mean Squared Error: {rmse}') #so on avergae I am missing by 0.83\n",
    "print(f'R^2 Score: {r2_score}') #again like this a debate of waht a good R**2 value is fora 20% test data and a ridge regress\n",
    "\n",
    "#Tuning the alpha hyperparameter using GridSearchCV\n",
    "alpha_values = {'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "ridge_cv = GridSearchCV(Ridge(), alpha_values, cv=5) # cv=5 = five fold cross validation. The model is trained on 4 subsets and validated on the remaining one. This process is repeated 5 times (each time with a different validation subset), and the results are averaged to assess the model's performance.\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Best alpha: {ridge_cv.best_params_[\"alpha\"]}') #retrieves the best alpha\n",
    "print(f'Best cross-validated score: {ridge_cv.best_score_}') #like best R**2 using th ebest alpha\n",
    "print('')\n",
    "\n",
    "#either way u spin it you have to choose a test size (%) and an alpha based on other aspects and not grid search cause drig search will make alpha 0 and test data small so unless u get better R^2 values for higher alpha and higher test then grid is illogical and the test_data split is pretty much depnedent on your horizon, alph is for how much u wanna avoid overfitting\n",
    "\n",
    "# Extract the coefficients and intercept\n",
    "coefficients = ridge_reg.coef_\n",
    "intercept = ridge_reg.intercept_\n",
    "\n",
    "# Display the coefficients and intercept\n",
    "print(\"Intercept (b0):\", intercept)\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    print(f\"Coefficient for {feature} (b_{feature}):\", coef)\n",
    "\n",
    "# Create the mathematical formula\n",
    "formula = \"PC3 = \" + f\"{intercept:.4f}\"\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    formula += f\" + ({coef:.4f}) * {feature}\"\n",
    "\n",
    "print(\"\\nMathematical formula for PC3:\")\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So PC1 will work but PC3 is not influenced by the macro indicators I compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
